# LLM API Keys (choose one or both)
ANTHROPIC_API_KEY=your_claude_api_key_here
OPENAI_API_KEY=your_openai_api_key_here

# Semantic Scholar API (optional but recommended)
SEMANTIC_SCHOLAR_API_KEY=your_semantic_scholar_key_here

# Vector Database Configuration
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=
QDRANT_COLLECTION=research_papers

# GPU Configuration
CUDA_VISIBLE_DEVICES=0
USE_GPU=true

# Embedding Configuration
EMBEDDING_MODEL=sentence-transformers/all-mpnet-base-v2
EMBEDDING_BATCH_SIZE=128
EMBEDDING_DEVICE=cuda

# Search Configuration
MAX_PAPERS_PER_SEARCH=20
MIN_CITATION_COUNT=10
DEFAULT_DATE_RANGE_YEARS=5

# Agent Configuration
AGENT_MAX_ITERATIONS=10
AGENT_TEMPERATURE=0.7
AGENT_MAX_TOKENS=2048

# Storage Paths
DATA_DIR=./data
PAPERS_DIR=./data/papers
EMBEDDINGS_DIR=./data/embeddings
METADATA_DIR=./data/metadata

# Logging
LOG_LEVEL=INFO
LOG_FILE=./logs/research_pilot.log

# Optional: Local LLM Configuration
USE_LOCAL_LLM=false
LOCAL_LLM_MODEL=meta-llama/Llama-3.1-8B-Instruct
LOCAL_LLM_GPU_MEMORY_UTILIZATION=0.85
